{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.distributions import Distribution, constraints\n",
    "from numpyro.distributions.util import validate_sample\n",
    "from numpyro.infer import MCMC, NUTS, Predictive, init_to_median\n",
    "import jax\n",
    "from jax import random\n",
    "from jax.scipy.stats import gaussian_kde\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1702560206.811986    4789 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n"
     ]
    }
   ],
   "source": [
    "# Create random seed for JAX\n",
    "rng_key = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTRIBUTIONS = {\n",
    "    \"normal\": dist.Normal,\n",
    "    \"half_normal\": dist.HalfNormal,\n",
    "    \"student_t\": dist.StudentT,\n",
    "    \"laplace\": dist.Laplace,\n",
    "    \"uniform\": dist.Uniform,\n",
    "    \"gamma\": dist.Gamma,\n",
    "    \"log-normal\": dist.LogNormal,\n",
    "    \"exponential\": dist.Exponential,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooled(X, y, ind, features_names, from_posterior=None, **init_params_kwargs):\n",
    "    prior_dist = init_params_kwargs.get(\"prior_dist\", \"normal\")\n",
    "    prior_params = init_params_kwargs.get(\"prior_params\", {\"loc\": 0, \"scale\": 1})\n",
    "    shape_dist = init_params_kwargs.get(\"shape_dist\", \"uniform\")\n",
    "    shape_params = init_params_kwargs.get(\"shape_params\", {\"low\": 1, \"high\": 100})\n",
    "    target_dist = init_params_kwargs.get(\"target_dist\", \"gamma\")\n",
    "\n",
    "    if from_posterior is None:\n",
    "        avg_salary = numpyro.sample(\"avg_salary\", DISTRIBUTIONS[prior_dist](**prior_params))\n",
    "        priors = []\n",
    "        for i, feature in enumerate(features_names):\n",
    "            priors.append(numpyro.sample(f\"beta_{feature}\", DISTRIBUTIONS[prior_dist](**prior_params)))\n",
    "    else:\n",
    "        avg_salary = numpyro.sample(\"avg_salary\", DISTRIBUTIONS[prior_dist](from_posterior[\"avg_salary\"].mean(), from_posterior[\"avg_salary\"].std()))\n",
    "        priors = []\n",
    "        for i, feature in enumerate(features_names):\n",
    "            priors.append(numpyro.sample(f\"beta_{feature}\", DISTRIBUTIONS[prior_dist](from_posterior[f\"beta_{feature}\"].mean(), from_posterior[f\"beta_{feature}\"].std())))\n",
    "    shape = numpyro.sample(\"shape\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "\n",
    "    # Expected value\n",
    "    mu = avg_salary\n",
    "    for i, prior in enumerate(priors):\n",
    "        mu += prior * X[:,i]\n",
    "    mu = jnp.exp(mu)\n",
    "    rate = shape / mu\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"data\", X.shape[0]):\n",
    "        numpyro.sample(\"salary_hat\", DISTRIBUTIONS[target_dist](concentration=shape, rate=rate), obs=y)\n",
    "\n",
    "def no_pooled_ind_occ(X, y, ind, occ, features_names, from_posterior=None, **init_params_kwargs):\n",
    "    # Initial parameters\n",
    "    prior_dist = init_params_kwargs.get(\"prior_dist\", \"normal\")\n",
    "    prior_params = init_params_kwargs.get(\"prior_params\", {\"loc\": 0, \"scale\": 1})\n",
    "    shape_dist = init_params_kwargs.get(\"shape_dist\", \"uniform\")\n",
    "    shape_params = init_params_kwargs.get(\"shape_params\", {\"low\": 1, \"high\": 100})\n",
    "    target_dist = init_params_kwargs.get(\"target_dist\", \"gamma\")\n",
    "\n",
    "    # Priors\n",
    "    priors_ind = []\n",
    "    priors_occ = []\n",
    "    if from_posterior is None:\n",
    "        with numpyro.plate(\"industry\", 16):\n",
    "            avg_salary_ind = numpyro.sample(\"avg_salary_ind\", DISTRIBUTIONS[prior_dist](**prior_params))\n",
    "            for i, feature in enumerate(features_names):\n",
    "                priors_ind.append(numpyro.sample(f\"beta_{feature}_ind\", DISTRIBUTIONS[prior_dist](**prior_params)))\n",
    "            shape_ind = numpyro.sample(\"shape_ind\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "\n",
    "        with numpyro.plate(\"occupation\", 24):\n",
    "            avg_salary_occ = numpyro.sample(\"avg_salary_occ\", DISTRIBUTIONS[prior_dist](**prior_params))\n",
    "            for i, feature in enumerate(features_names):\n",
    "                priors_occ.append(numpyro.sample(f\"beta_{feature}_occ\", DISTRIBUTIONS[prior_dist](**prior_params)))\n",
    "            shape_occ = numpyro.sample(\"shape_occ\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "    else:\n",
    "        with numpyro.plate(\"industry\", 16):\n",
    "            avg_salary_ind = numpyro.sample(\"avg_salary_ind\", \n",
    "                                        DISTRIBUTIONS[prior_dist](from_posterior[\"avg_salary_ind\"].mean(axis=0), from_posterior[\"avg_salary_ind\"].std(axis=0)))\n",
    "            for i, feature in enumerate(features_names):\n",
    "                priors_ind.append(numpyro.sample(f\"beta_{feature}_ind\", \n",
    "                                             DISTRIBUTIONS[prior_dist](from_posterior[f\"beta_{feature}_ind\"].mean(axis=0), from_posterior[f\"beta_{feature}_ind\"].std(axis=0))))\n",
    "            shape_ind = numpyro.sample(\"shape_ind\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "        \n",
    "        with numpyro.plate(\"occupation\", 24):\n",
    "            avg_salary_occ = numpyro.sample(\"avg_salary_occ\", \n",
    "                                        DISTRIBUTIONS[prior_dist](from_posterior[\"avg_salary_occ\"].mean(axis=0), from_posterior[\"avg_salary_occ\"].std(axis=0)))\n",
    "            for i, feature in enumerate(features_names):\n",
    "                priors_occ.append(numpyro.sample(f\"beta_{feature}_occ\", \n",
    "                                             DISTRIBUTIONS[prior_dist](from_posterior[f\"beta_{feature}_occ\"].mean(axis=0), from_posterior[f\"beta_{feature}_occ\"].std(axis=0))))\n",
    "            shape_occ = numpyro.sample(\"shape_occ\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "\n",
    "    # Expected value\n",
    "    mu = avg_salary_ind[ind] + avg_salary_occ[occ]\n",
    "    for i, feature in enumerate(features_names):\n",
    "        mu += priors_ind[i][ind] * X[:,i] + priors_occ[i][occ] * X[:,i]\n",
    "\n",
    "    shape = shape_ind[ind] + shape_occ[occ]\n",
    "\n",
    "    mu = jnp.exp(mu)\n",
    "    rate = shape / mu\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"data\", X.shape[0]):\n",
    "        numpyro.sample(\"salary_hat\", DISTRIBUTIONS[target_dist](concentration=shape, rate=rate), obs=y)\n",
    "\n",
    "def hierarchical_ind_occ(X, y, ind, occ, features_names, from_posterior=None, **init_params_kwargs):\n",
    "    # Initial parameters\n",
    "    mu_dist = init_params_kwargs.get(\"mu_dist\", \"normal\")\n",
    "    mu_params = init_params_kwargs.get(\"mu_params\", {\"loc\": 0, \"scale\": 3})\n",
    "    sigma_dist = init_params_kwargs.get(\"sigma_dist\", \"half_normal\")\n",
    "    sigma_params = init_params_kwargs.get(\"sigma_params\", {\"scale\": 3})\n",
    "    shape_dist = init_params_kwargs.get(\"shape_dist\", \"uniform\")\n",
    "    shape_params = init_params_kwargs.get(\"shape_params\", {\"low\": 1, \"high\": 100})\n",
    "    target_dist = init_params_kwargs.get(\"target_dist\", \"gamma\")\n",
    "\n",
    "    # Hyperpriors\n",
    "    mus_ind = []\n",
    "    sigmas_ind = []\n",
    "    mus_occ = []\n",
    "    sigmas_occ = []\n",
    "    for dim in [\"ind\", \"occ\"]:\n",
    "        if from_posterior is None:\n",
    "            if dim == \"ind\":\n",
    "                mu_avg_salary_ind = numpyro.sample(f\"mu_avg_salary_ind\", DISTRIBUTIONS[mu_dist](**mu_params))\n",
    "                sigma_avg_salary_ind = numpyro.sample(f\"sigma_avg_salary_ind\", DISTRIBUTIONS[sigma_dist](**sigma_params))\n",
    "                for feature in features_names:\n",
    "                    mus_ind.append(numpyro.sample(f\"mu_{feature}_{dim}\", DISTRIBUTIONS[mu_dist](**mu_params)))\n",
    "                    sigmas_ind.append(numpyro.sample(f\"sigma_{feature}_{dim}\", DISTRIBUTIONS[sigma_dist](**sigma_params)))\n",
    "            else:\n",
    "                mu_avg_salary_occ = numpyro.sample(f\"mu_avg_salary_occ\", DISTRIBUTIONS[mu_dist](**mu_params))\n",
    "                sigma_avg_salary_occ = numpyro.sample(f\"sigma_avg_salary_occ\", DISTRIBUTIONS[sigma_dist](**sigma_params))\n",
    "                for feature in features_names:\n",
    "                    mus_occ.append(numpyro.sample(f\"mu_{feature}_{dim}\", DISTRIBUTIONS[mu_dist](**mu_params)))\n",
    "                    sigmas_occ.append(numpyro.sample(f\"sigma_{feature}_{dim}\", DISTRIBUTIONS[sigma_dist](**sigma_params)))\n",
    "            \n",
    "        else:\n",
    "            if dim == \"ind\":\n",
    "                mu_avg_salary_ind = numpyro.sample(f\"mu_avg_salary_ind\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_avg_salary_ind\"].mean(axis=0), \n",
    "                                                                   from_posterior[f\"mu_avg_salary_ind\"].std(axis=0)))\n",
    "                sigma_avg_salary_ind = numpyro.sample(f\"sigma_avg_salary_ind\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_avg_salary_ind\"].mean(axis=0)))\n",
    "                for feature in features_names:\n",
    "                    mus_ind.append(numpyro.sample(f\"mu_{feature}_{dim}\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_{feature}_{dim}\"].mean(axis=0), \n",
    "                                                                   from_posterior[f\"mu_{feature}_{dim}\"].std(axis=0))))\n",
    "                    sigmas_ind.append(numpyro.sample(f\"sigma_{feature}_{dim}\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_{feature}_{dim}\"].mean(axis=0))))\n",
    "            else:\n",
    "                mu_avg_salary_occ = numpyro.sample(f\"mu_avg_salary_occ\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_avg_salary_occ\"].mean(axis=0), \n",
    "                                                                   from_posterior[f\"mu_avg_salary_occ\"].std(axis=0)))\n",
    "                sigma_avg_salary_occ = numpyro.sample(f\"sigma_avg_salary_occ\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_avg_salary_occ\"].mean(axis=0)))\n",
    "                for feature in features_names:\n",
    "                    mus_occ.append(numpyro.sample(f\"mu_{feature}_{dim}\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_{feature}_{dim}\"].mean(axis=0), \n",
    "                                                                   from_posterior[f\"mu_{feature}_{dim}\"].std(axis=0))))\n",
    "                    sigmas_occ.append(numpyro.sample(f\"sigma_{feature}_{dim}\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_{feature}_{dim}\"].mean(axis=0))))\n",
    "            \n",
    "    priors_ind = []\n",
    "    priors_occ = []\n",
    "    with numpyro.plate(f\"industry\", 16):\n",
    "        offset_avg_salary_ind = numpyro.sample(f\"offset_avg_salary_ind\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "        avg_salary_ind = numpyro.deterministic(f\"avg_salary_ind\", mu_avg_salary_ind + offset_avg_salary_ind * sigma_avg_salary_ind)\n",
    "        for i, feature in enumerate(features_names):\n",
    "            offset = numpyro.sample(f\"offset_{feature}_ind\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "            priors_ind.append(numpyro.deterministic(f\"beta_{feature}_ind\", mus_ind[i] + offset * sigmas_ind[i]))\n",
    "        shape_ind = numpyro.sample(\"shape_ind\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "    \n",
    "    with numpyro.plate(f\"occupation\", 24):\n",
    "        offset_avg_salary_occ = numpyro.sample(f\"offset_avg_salary_occ\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "        avg_salary_occ = numpyro.deterministic(f\"avg_salary_occ\", mu_avg_salary_occ + offset_avg_salary_occ * sigma_avg_salary_occ)\n",
    "        for i, feature in enumerate(features_names):\n",
    "            offset = numpyro.sample(f\"offset_{feature}_occ\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "            priors_occ.append(numpyro.deterministic(f\"beta_{feature}_occ\", mus_occ[i] + offset * sigmas_occ[i]))\n",
    "        shape_occ = numpyro.sample(\"shape_occ\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "\n",
    "\n",
    "    # Expected value\n",
    "    mu = avg_salary_ind[ind] + avg_salary_occ[occ]\n",
    "    for i, feature in enumerate(features_names):\n",
    "        mu += priors_ind[i][ind] * X[:,i] + priors_occ[i][occ] * X[:,i]\n",
    "\n",
    "    shape = shape_ind[ind] + shape_occ[occ]\n",
    "\n",
    "    mu = jnp.exp(mu)\n",
    "    rate = shape / mu\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"data\", X.shape[0]):\n",
    "        numpyro.sample(\"salary_hat\", DISTRIBUTIONS[target_dist](concentration=shape, rate=rate), obs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(year, data, columns=None, occ_dim=False, samples=None):\n",
    "    # Prepare data for running the model\n",
    "    if columns is None:\n",
    "        columns = [\"exp\",\"sex\",\"no_edu\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "                \"undergrad_edu\", \"graduate_edu\", \"age\", \"tenure\", \"union\", \"public_sector\", \"self_emp\"]\n",
    "        \n",
    "    if samples is None:\n",
    "        dataset = data.query(f'year == {year}').copy()\n",
    "    else:\n",
    "        dataset = data.query(f'year == {year}').sample(samples, random_state=0).copy()\n",
    "\n",
    "    X = dataset[columns].values\n",
    "    y = dataset[\"salary\"].values\n",
    "    ind = dataset[\"ind_codes\"].values\n",
    "    occ = dataset[\"occ_codes\"].values\n",
    "    if occ_dim:\n",
    "        return X, y, ind, occ\n",
    "    else:\n",
    "        return X, y, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_type):\n",
    "    if model_type == \"pooled\":\n",
    "        return pooled\n",
    "    elif model_type == \"no_pooled_ind_occ\":\n",
    "        return no_pooled_ind_occ\n",
    "    elif model_type == \"hierarchical_ind_occ\":\n",
    "        return hierarchical_ind_occ\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_coords(mcmc, dimensions, categories, data):\n",
    "    model_coords = {\"coords\": {dim: categories[i] for i, dim in enumerate(dimensions)}}\n",
    "    model_coords[\"coords\"][\"obs\"] = np.arange(0,data.shape[0])\n",
    "    model_coords[\"dims\"] = {}\n",
    "    for latent_var in mcmc._states['z'].keys():\n",
    "        if any(latent_var.startswith(field) for field in [\"avg_\",\"beta_\"]):\n",
    "            model_coords[\"dims\"][latent_var] = [\"industry\"] if latent_var.endswith(\"ind\") else [\"occupation\"]\n",
    "    return model_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model_outputs(mcmc, model, path, *model_params, **model_coords):\n",
    "    # Export mcmc\n",
    "    with open(f\"{path}/model.pickle\", \"wb\") as file:\n",
    "        pickle.dump(mcmc, file)\n",
    "    # Create posterior predictive samples\n",
    "    predictive = Predictive(model, mcmc.get_samples())\n",
    "    posterior_samples = predictive(rng_key, *model_params)\n",
    "    # Add posterior predictive samples to trace\n",
    "    if model_coords=={}:\n",
    "        trace = az.from_numpyro(mcmc, posterior_predictive=posterior_samples)\n",
    "    else:\n",
    "        trace = az.from_numpyro(mcmc, posterior_predictive=posterior_samples, coords=model_coords[\"coords\"], dims=model_coords[\"dims\"])\n",
    "    # Export trace\n",
    "    trace.to_netcdf(f\"{path}/trace.nc\")\n",
    "    # Export summary\n",
    "    summary = az.summary(trace, round_to=5)\n",
    "    summary.to_csv(f\"{path}/summary.csv\")\n",
    "    # Return max Rhat\n",
    "    return summary[\"r_hat\"].max()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and workflow\n",
    "data = pd.read_csv('../datasets/model_dataset_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert industries and occupations to categorical and create codes columns\n",
    "ind_cat = [\n",
    "    'agriculture',\n",
    "    'forestry/oil/mining',\n",
    "    'utilities',\n",
    "    'construction',\n",
    "    'manufacturing',\n",
    "    'trade',\n",
    "    'transportation',\n",
    "    'info/culture',\n",
    "    'finance/real estate',\n",
    "    'scientific/technical',\n",
    "    'business support',\n",
    "    'education',\n",
    "    'health/social',\n",
    "    'accommodation/food',\n",
    "    'other services',\n",
    "    'public admin']\n",
    "data[\"industry\"] = pd.Categorical(data[\"industry\"], categories=ind_cat)\n",
    "data[\"ind_codes\"] = data[\"industry\"].cat.codes\n",
    "\n",
    "occ_cat = ['senior management',\n",
    "    'middle management',\n",
    "    'business/finance professional',\n",
    "    'secretarial/administrative',\n",
    "    'natural/sciences professional',\n",
    "    'technical specialist',\n",
    "    'health professional',\n",
    "    'health assistant',\n",
    "    'teachers/professors',\n",
    "    'government/religion services',\n",
    "    'protective services',\n",
    "    'childcare/home support',\n",
    "    'art/culture occupations',\n",
    "    'clerical/supervisor',\n",
    "    'chefs/food services',\n",
    "    'sales/service',\n",
    "    'clerks/cashiers',\n",
    "    'construction trades',\n",
    "    'transport/equipment operators',\n",
    "    'trade helper/labourer',\n",
    "    'trades contractors/supervisors',\n",
    "    'other trades',\n",
    "    'operators/assemblers',\n",
    "    'manufacturing labourer']\n",
    "data[\"occup\"] = pd.Categorical(data[\"occup\"], categories=occ_cat)\n",
    "data[\"occ_codes\"] = data[\"occup\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique years and sort them\n",
    "years = data[\"year\"].unique()\n",
    "years.sort()\n",
    "\n",
    "# Define features\n",
    "feature_names = [\"exp\",\"sex\",\"no_edu\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "\"undergrad_edu\", \"graduate_edu\", \"age\", \"tenure\", \"union\", \"public_sector\", \"self_emp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split (training and testing)\n",
    "# NOTE: Data before 2008 is used for training and data after 2008 is used for validating the model\n",
    "data = data.query(\"year < 2008\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to store standardization parameters\n",
    "standardization_params = {\n",
    "    \"exp\": {\"mean\": data[\"exp\"].mean(), \"std\": data[\"exp\"].std()},\n",
    "    \"age\": {\"mean\": data[\"age\"].mean(), \"std\": data[\"age\"].std()},\n",
    "    \"tenure\": {\"mean\": data[\"tenure\"].mean(), \"std\": data[\"tenure\"].std()}\n",
    "}\n",
    "\n",
    "# Export standardization parameters (for be used in the validation step)\n",
    "with open(\"src/standardization_params.json\", \"w\") as file:\n",
    "    json.dump(standardization_params, file)\n",
    "\n",
    "# Standardize data\n",
    "data[\"exp\"] = (data[\"exp\"] - data[\"exp\"].mean()) / data[\"exp\"].std()\n",
    "data[\"age\"] = (data[\"age\"] - data[\"age\"].mean()) / data[\"age\"].std()\n",
    "data[\"tenure\"] = (data[\"tenure\"] - data[\"tenure\"].mean()) / data[\"tenure\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"pooled\"\n",
    "model_type = \"pooled\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:10<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00421\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:12<00:00, 15.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00822\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:09<00:00, 28.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00494\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:34<00:00, 57.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0022\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:24<00:00, 81.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0026\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:25<00:00, 78.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0022\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:22<00:00, 88.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00231\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:23<00:00, 83.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00228\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:21<00:00, 91.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00228\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:29<00:00, 66.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00326\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:23<00:00, 83.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00224\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:24<00:00, 82.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00303\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, ind = filter_data(year, data)\n",
    "    # Run model\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, feature_names]\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No-pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"no-pooled\"\n",
    "model_type = \"no_pooled_ind_occ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:44:29<00:00,  4.93s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01184\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [32:45<00:00,  1.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00921\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [19:36<00:00,  1.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00636\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [16:48<00:00,  1.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00693\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [12:06<00:00,  2.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00761\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:05<00:00, 15.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00544\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [09:09<00:00,  3.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00487\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [09:03<00:00,  3.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00494\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [08:37<00:00,  3.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00591\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [08:55<00:00,  3.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00636\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [09:27<00:00,  3.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00706\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [08:38<00:00,  3.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00738\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, ind, occ = filter_data(year, data, columns=None, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, feature_names)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, feature_names]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, feature_names, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"hierarchical-ind-occ\"\n",
    "model_type = \"hierarchical_ind_occ\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/hierarchical-ind-occ/1999/model.pickle\", \"rb\") as file:\n",
    "    mcmc = pickle.load(file)\n",
    "samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:48:06<00:00,  5.04s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01917\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [25:43<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00697\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:43:37<00:00,  4.91s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00957\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:38:07<00:00,  4.74s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00893\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:32:47<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00796\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:29:29<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00944\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:26:47<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00554\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [49:40<00:00,  1.49s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00878\n"
     ]
    }
   ],
   "source": [
    "years = list(range(2000, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, ind, occ = filter_data(year, data, columns=None, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, feature_names)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, feature_names]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, feature_names, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, feature_names]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models (variable selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS1 - NO self_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS1-no_self\"\n",
    "model_type = \"hierarchical_ind_occ\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/VS1-no_self/2005/model.pickle\", \"rb\") as file:\n",
    "    mcmc = pickle.load(file)\n",
    "samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [50:04<00:00,  1.50s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00727\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [43:29<00:00,  1.30s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00931\n"
     ]
    }
   ],
   "source": [
    "years = list(range(2006, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\",\"sex\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "                \"undergrad_edu\", \"graduate_edu\", \"age\", \"tenure\", \"union\", \"public_sector\"]\n",
    "    X, y, ind, occ = filter_data(year, data, columns=columns, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, columns]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, columns]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS2 - NO public sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS2-no_public\"\n",
    "model_type = \"hierarchical_ind_occ\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:41:20<00:00,  4.84s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.30492\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:38:43<00:00,  4.76s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.1172\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:42:24<00:00,  4.87s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.03316\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:37:53<00:00,  4.74s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01834\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:38:50<00:00,  4.77s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01429\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [11:39<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00732\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:02:59<00:00,  3.69s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01419\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:24:12<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00873\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:13:24<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00936\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [49:50<00:00,  1.50s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00555\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [48:15<00:00,  1.45s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00679\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [30:03<00:00,  1.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0076\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\",\"sex\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "                \"undergrad_edu\", \"graduate_edu\", \"age\", \"tenure\", \"union\"]\n",
    "    X, y, ind, occ = filter_data(year, data, columns=columns, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, columns]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS3 - NO union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS3-no_union\"\n",
    "model_type = \"hierarchical_ind_occ\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [3:00:37<00:00,  5.42s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.50904\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:44:31<00:00,  4.94s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.16325\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:42:40<00:00,  4.88s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.09388\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:37:27<00:00,  4.72s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.05701\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:39:12<00:00,  4.78s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.02636\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [11:01<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00603\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:27:02<00:00,  4.41s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0077\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:25:32<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00795\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:15:57<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0098\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [50:06<00:00,  1.50s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01189\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [48:21<00:00,  1.45s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00839\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [30:57<00:00,  1.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01163\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\",\"sex\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "                \"undergrad_edu\", \"graduate_edu\", \"age\", \"tenure\"]\n",
    "    X, y, ind, occ = filter_data(year, data, columns=columns, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, columns]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS4 - NO tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS4-no_tenure\"\n",
    "model_type = \"hierarchical_ind_occ\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:50:44<00:00,  5.12s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.2246\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:58:42<00:00,  5.36s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.05379\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [3:00:33<00:00,  5.42s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.02247\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:51:39<00:00,  5.15s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01598\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:46:56<00:00,  5.01s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00695\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [10:29<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00616\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:44:28<00:00,  3.13s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01257\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:25:57<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01578\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [55:35<00:00,  1.67s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00716\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [50:17<00:00,  1.51s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0108\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [51:23<00:00,  1.54s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00667\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [30:12<00:00,  1.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0161\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\",\"sex\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "                \"undergrad_edu\", \"graduate_edu\", \"age\"]\n",
    "    X, y, ind, occ = filter_data(year, data, columns=columns, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, columns]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS5 - NO Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS5-no_age\"\n",
    "model_type = \"hierarchical_ind_occ\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/VS5-no_age/1998/model.pickle\", \"rb\") as file:\n",
    "    mcmc = pickle.load(file)\n",
    "samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:33:39<00:00,  4.61s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01093\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:35:33<00:00,  4.67s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00871\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [08:56<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00699\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:31:30<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00769\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:21:31<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00931\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [47:26<00:00,  1.42s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00691\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [45:59<00:00,  1.38s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00612\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [34:57<00:00,  1.05s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01407\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [26:45<00:00,  1.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00877\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1999, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\",\"sex\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "                \"undergrad_edu\", \"graduate_edu\"]\n",
    "    X, y, ind, occ = filter_data(year, data, columns=columns, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, columns]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, columns]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS6 - NO Education Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS6-no_edu\"\n",
    "model_type = \"hierarchical_ind_occ\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/VS6-no_edu/1997/model.pickle\", \"rb\") as file:\n",
    "    mcmc = pickle.load(file)\n",
    "samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:09:46<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.04588\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:09:11<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.02692\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:25:55<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01098\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [07:32<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00506\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [40:03<00:00,  1.20s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00388\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [35:39<00:00,  1.07s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00804\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [19:50<00:00,  1.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00731\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [20:39<00:00,  1.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00524\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [14:38<00:00,  2.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01499\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [11:14<00:00,  2.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00778\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1998, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\",\"sex\"]\n",
    "    X, y, ind, occ = filter_data(year, data, columns=columns, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, columns]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, columns]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS7 - No Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS7-no_sex\"\n",
    "model_type = \"hierarchical_ind_occ\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:06:05<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.15142\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:02:53<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.04196\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:04:39<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01609\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:03:40<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00728\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:02:12<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0114\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [04:18<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00791\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [37:13<00:00,  1.12s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00815\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [19:13<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01435\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [19:02<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00796\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [15:23<00:00,  2.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0128\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [11:36<00:00,  2.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0081\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [10:41<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00953\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\"]\n",
    "    X, y, ind, occ = filter_data(year, data, columns=columns, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, columns]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS8 - No exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS8-no_exp\"\n",
    "model_type = \"hierarchical_ind_occ\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/VS8-no_exp/1996/model.pickle\", \"rb\") as file:\n",
    "    mcmc = pickle.load(file)\n",
    "samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:02:28<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.08313\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:03:45<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.03699\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:02:02<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01461\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [56:57<00:00,  1.71s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0107\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [03:59<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0091\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [34:26<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01093\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [27:32<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.008\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [20:13<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00994\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [17:39<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01386\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [15:19<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01035\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [11:10<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00872\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1997, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = []\n",
    "    X, y, ind, occ = filter_data(year, data, columns=columns, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, columns]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, columns]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
