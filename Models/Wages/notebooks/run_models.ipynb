{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.distributions import Distribution, constraints\n",
    "from numpyro.distributions.util import validate_sample\n",
    "from numpyro.infer import MCMC, NUTS, Predictive, init_to_median\n",
    "import jax\n",
    "from jax import random\n",
    "from jax.scipy.stats import gaussian_kde\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1698929558.171491    4381 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n"
     ]
    }
   ],
   "source": [
    "# Create random seed for JAX\n",
    "rng_key = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTRIBUTIONS = {\n",
    "    \"normal\": dist.Normal,\n",
    "    \"half_normal\": dist.HalfNormal,\n",
    "    \"student_t\": dist.StudentT,\n",
    "    \"laplace\": dist.Laplace,\n",
    "    \"uniform\": dist.Uniform,\n",
    "    \"gamma\": dist.Gamma,\n",
    "    \"log-normal\": dist.LogNormal,\n",
    "    \"exponential\": dist.Exponential,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooled(X, y, ind, features_names, from_posterior=None, **init_params_kwargs):\n",
    "    prior_dist = init_params_kwargs.get(\"prior_dist\", \"normal\")\n",
    "    prior_params = init_params_kwargs.get(\"prior_params\", {\"loc\": 0, \"scale\": 1})\n",
    "    shape_dist = init_params_kwargs.get(\"shape_dist\", \"uniform\")\n",
    "    shape_params = init_params_kwargs.get(\"shape_params\", {\"low\": 1, \"high\": 100})\n",
    "    target_dist = init_params_kwargs.get(\"target_dist\", \"gamma\")\n",
    "\n",
    "    if from_posterior is None:\n",
    "        avg_salary = numpyro.sample(\"avg_salary\", DISTRIBUTIONS[prior_dist](**prior_params))\n",
    "        priors = []\n",
    "        for i, feature in enumerate(features_names):\n",
    "            priors.append(numpyro.sample(f\"beta_{feature}\", DISTRIBUTIONS[prior_dist](**prior_params)))\n",
    "    else:\n",
    "        avg_salary = numpyro.sample(\"avg_salary\", DISTRIBUTIONS[prior_dist](from_posterior[\"avg_salary\"].mean(), from_posterior[\"avg_salary\"].std()))\n",
    "        priors = []\n",
    "        for i, feature in enumerate(features_names):\n",
    "            priors.append(numpyro.sample(f\"beta_{feature}\", DISTRIBUTIONS[prior_dist](from_posterior[f\"beta_{feature}\"].mean(), from_posterior[f\"beta_{feature}\"].std())))\n",
    "    shape = numpyro.sample(\"shape\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "\n",
    "    # Expected value\n",
    "    mu = avg_salary\n",
    "    for i, prior in enumerate(priors):\n",
    "        mu += prior * X[:,i]\n",
    "    mu = jnp.exp(mu)\n",
    "    rate = shape / mu\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"data\", X.shape[0]):\n",
    "        numpyro.sample(\"salary_hat\", DISTRIBUTIONS[target_dist](concentration=shape, rate=rate), obs=y)\n",
    "\n",
    "def no_pooled_ind(X, y, ind, features_names, from_posterior=None, **init_params_kwargs):\n",
    "    # Initial parameters\n",
    "    prior_dist = init_params_kwargs.get(\"prior_dist\", \"normal\")\n",
    "    prior_params = init_params_kwargs.get(\"prior_params\", {\"loc\": 0, \"scale\": 1})\n",
    "    shape_dist = init_params_kwargs.get(\"shape_dist\", \"uniform\")\n",
    "    shape_params = init_params_kwargs.get(\"shape_params\", {\"low\": 1, \"high\": 100})\n",
    "    target_dist = init_params_kwargs.get(\"target_dist\", \"gamma\")\n",
    "\n",
    "    # Priors\n",
    "    if from_posterior is None:\n",
    "        with numpyro.plate(\"industry\", 16):\n",
    "            avg_salary = numpyro.sample(\"avg_salary\", DISTRIBUTIONS[prior_dist](**prior_params))\n",
    "            priors = []\n",
    "            for i, feature in enumerate(features_names):\n",
    "                priors.append(numpyro.sample(f\"beta_{feature}\", DISTRIBUTIONS[prior_dist](**prior_params)))\n",
    "            shape = numpyro.sample(\"shape\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "    else:\n",
    "        with numpyro.plate(\"industry\", 16):\n",
    "            avg_salary = numpyro.sample(\"avg_salary\", \n",
    "                                        DISTRIBUTIONS[prior_dist](from_posterior[\"avg_salary\"].mean(axis=0), from_posterior[\"avg_salary\"].std(axis=0)))\n",
    "            priors = []\n",
    "            for i, feature in enumerate(features_names):\n",
    "                priors.append(numpyro.sample(f\"beta_{feature}\", \n",
    "                                             DISTRIBUTIONS[prior_dist](from_posterior[f\"beta_{feature}\"].mean(axis=0), from_posterior[f\"beta_{feature}\"].std(axis=0))))\n",
    "            shape = numpyro.sample(\"shape\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "\n",
    "    # Expected value\n",
    "    mu = avg_salary[ind]\n",
    "    for i, prior in enumerate(priors):\n",
    "        mu += prior[ind] * X[:,i]\n",
    "    mu = jnp.exp(mu)\n",
    "    rate = shape[ind] / mu\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"data\", X.shape[0]):\n",
    "        numpyro.sample(\"salary_hat\", DISTRIBUTIONS[target_dist](concentration=shape[ind], rate=rate), obs=y)\n",
    "\n",
    "def no_pooled_occ(X, y, occ, features_names, from_posterior=None, **init_params_kwargs):\n",
    "    # Initial parameters\n",
    "    prior_dist = init_params_kwargs.get(\"prior_dist\", \"normal\")\n",
    "    prior_params = init_params_kwargs.get(\"prior_params\", {\"loc\": 0, \"scale\": 1})\n",
    "    shape_dist = init_params_kwargs.get(\"shape_dist\", \"uniform\")\n",
    "    shape_params = init_params_kwargs.get(\"shape_params\", {\"low\": 1, \"high\": 100})\n",
    "    target_dist = init_params_kwargs.get(\"target_dist\", \"gamma\")\n",
    "\n",
    "    # Priors\n",
    "    if from_posterior is None:\n",
    "        with numpyro.plate(\"occupation\", 24):\n",
    "            avg_salary = numpyro.sample(\"avg_salary\", DISTRIBUTIONS[prior_dist](**prior_params))\n",
    "            priors = []\n",
    "            for i, feature in enumerate(features_names):\n",
    "                priors.append(numpyro.sample(f\"beta_{feature}\", DISTRIBUTIONS[prior_dist](**prior_params)))\n",
    "            shape = numpyro.sample(\"shape\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "    else:\n",
    "        with numpyro.plate(\"occupation\", 24):\n",
    "            avg_salary = numpyro.sample(\"avg_salary\", \n",
    "                                        DISTRIBUTIONS[prior_dist](from_posterior[\"avg_salary\"].mean(axis=0), from_posterior[\"avg_salary\"].std(axis=0)))\n",
    "            priors = []\n",
    "            for i, feature in enumerate(features_names):\n",
    "                priors.append(numpyro.sample(f\"beta_{feature}\", \n",
    "                                             DISTRIBUTIONS[prior_dist](from_posterior[f\"beta_{feature}\"].mean(axis=0), from_posterior[f\"beta_{feature}\"].std(axis=0))))\n",
    "            shape = numpyro.sample(\"shape\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "\n",
    "    # Expected value\n",
    "    mu = avg_salary[occ]\n",
    "    for i, prior in enumerate(priors):\n",
    "        mu += prior[occ] * X[:,i]\n",
    "    mu = jnp.exp(mu)\n",
    "    rate = shape[occ] / mu\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"data\", X.shape[0]):\n",
    "        numpyro.sample(\"salary_hat\", DISTRIBUTIONS[target_dist](concentration=shape[occ], rate=rate), obs=y)\n",
    "\n",
    "def hierarchical_ind(X, y, ind, features_names, from_posterior=None, **init_params_kwargs):\n",
    "    # Initial parameters\n",
    "    mu_dist = init_params_kwargs.get(\"mu_dist\", \"normal\")\n",
    "    mu_params = init_params_kwargs.get(\"mu_params\", {\"loc\": 0, \"scale\": 3})\n",
    "    sigma_dist = init_params_kwargs.get(\"sigma_dist\", \"half_normal\")\n",
    "    sigma_params = init_params_kwargs.get(\"sigma_params\", {\"scale\": 3})\n",
    "    shape_dist = init_params_kwargs.get(\"shape_dist\", \"uniform\")\n",
    "    shape_params = init_params_kwargs.get(\"shape_params\", {\"low\": 1, \"high\": 100})\n",
    "    target_dist = init_params_kwargs.get(\"target_dist\", \"gamma\")\n",
    "\n",
    "    # Hyperpriors\n",
    "    mus = []\n",
    "    sigmas = []\n",
    "    if from_posterior is None:\n",
    "        mu_avg_salary = numpyro.sample(\"mu_avg_salary\", DISTRIBUTIONS[mu_dist](**mu_params))\n",
    "        sigma_avg_salary = numpyro.sample(\"sigma_avg_salary\", DISTRIBUTIONS[sigma_dist](**sigma_params))\n",
    "        \n",
    "        for feature in features_names:\n",
    "            mus.append(numpyro.sample(f\"mu_{feature}\", DISTRIBUTIONS[mu_dist](**mu_params)))\n",
    "            sigmas.append(numpyro.sample(f\"sigma_{feature}\", DISTRIBUTIONS[sigma_dist](**sigma_params)))\n",
    "    else:\n",
    "        mu_avg_salary = numpyro.sample(\"mu_avg_salary\", \n",
    "                                       DISTRIBUTIONS[mu_dist](from_posterior[\"mu_avg_salary\"].mean(axis=0), from_posterior[\"mu_avg_salary\"].std(axis=0)))\n",
    "        sigma_avg_salary = numpyro.sample(\"sigma_avg_salary\", \n",
    "                                          DISTRIBUTIONS[sigma_dist](from_posterior[\"sigma_avg_salary\"].mean(axis=0)))\n",
    "        \n",
    "        for feature in features_names:\n",
    "            mus.append(numpyro.sample(f\"mu_{feature}\", \n",
    "                                      DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_{feature}\"].mean(axis=0), from_posterior[f\"mu_{feature}\"].std(axis=0))))\n",
    "            sigmas.append(numpyro.sample(f\"sigma_{feature}\", \n",
    "                                         DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_{feature}\"].mean(axis=0))))\n",
    "\n",
    "    with numpyro.plate(f\"industry\", 16):\n",
    "        offset_avg_salary = numpyro.sample(\"offset_avg_salary\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "        avg_salary = numpyro.deterministic(\"avg_salary\", mu_avg_salary + offset_avg_salary * sigma_avg_salary)\n",
    "        priors = []\n",
    "        for i, feature in enumerate(features_names):\n",
    "            offset = numpyro.sample(f\"offset_{feature}\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "            priors.append(numpyro.deterministic(f\"beta_{feature}\", mus[i] + offset * sigmas[i]))\n",
    "        shape = numpyro.sample(\"shape\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "\n",
    "    # Expected value\n",
    "    mu = avg_salary[ind]\n",
    "    for i, feature in enumerate(features_names):\n",
    "        mu += priors[i][ind] * X[:,i]\n",
    "\n",
    "    mu = jnp.exp(mu)\n",
    "    rate = shape[ind] / mu\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"data\", X.shape[0]):\n",
    "        numpyro.sample(\"salary_hat\", DISTRIBUTIONS[target_dist](concentration=shape[ind], rate=rate), obs=y)\n",
    "\n",
    "def hierarchical_occ(X, y, occ, features_names, from_posterior=None, **init_params_kwargs):\n",
    "    # Initial parameters\n",
    "    mu_dist = init_params_kwargs.get(\"mu_dist\", \"normal\")\n",
    "    mu_params = init_params_kwargs.get(\"mu_params\", {\"loc\": 0, \"scale\": 3})\n",
    "    sigma_dist = init_params_kwargs.get(\"sigma_dist\", \"half_normal\")\n",
    "    sigma_params = init_params_kwargs.get(\"sigma_params\", {\"scale\": 3})\n",
    "    shape_dist = init_params_kwargs.get(\"shape_dist\", \"uniform\")\n",
    "    shape_params = init_params_kwargs.get(\"shape_params\", {\"low\": 1, \"high\": 100})\n",
    "    target_dist = init_params_kwargs.get(\"target_dist\", \"gamma\")\n",
    "\n",
    "    # Hyperpriors\n",
    "    mus = []\n",
    "    sigmas = []\n",
    "    if from_posterior is None:\n",
    "        mu_avg_salary = numpyro.sample(\"mu_avg_salary\", DISTRIBUTIONS[mu_dist](**mu_params))\n",
    "        sigma_avg_salary = numpyro.sample(\"sigma_avg_salary\", DISTRIBUTIONS[sigma_dist](**sigma_params))\n",
    "        \n",
    "        for feature in features_names:\n",
    "            mus.append(numpyro.sample(f\"mu_{feature}\", DISTRIBUTIONS[mu_dist](**mu_params)))\n",
    "            sigmas.append(numpyro.sample(f\"sigma_{feature}\", DISTRIBUTIONS[sigma_dist](**sigma_params)))\n",
    "    else:\n",
    "        mu_avg_salary = numpyro.sample(\"mu_avg_salary\", \n",
    "                                       DISTRIBUTIONS[mu_dist](from_posterior[\"mu_avg_salary\"].mean(axis=0), from_posterior[\"mu_avg_salary\"].std(axis=0)))\n",
    "        sigma_avg_salary = numpyro.sample(\"sigma_avg_salary\", \n",
    "                                          DISTRIBUTIONS[sigma_dist](from_posterior[\"sigma_avg_salary\"].mean(axis=0)))\n",
    "        \n",
    "        for feature in features_names:\n",
    "            mus.append(numpyro.sample(f\"mu_{feature}\", \n",
    "                                      DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_{feature}\"].mean(axis=0), from_posterior[f\"mu_{feature}\"].std(axis=0))))\n",
    "            sigmas.append(numpyro.sample(f\"sigma_{feature}\", \n",
    "                                         DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_{feature}\"].mean(axis=0))))\n",
    "\n",
    "    with numpyro.plate(f\"occupation\", 24):\n",
    "        offset_avg_salary = numpyro.sample(\"offset_avg_salary\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "        avg_salary = numpyro.deterministic(\"avg_salary\", mu_avg_salary + offset_avg_salary * sigma_avg_salary)\n",
    "        priors = []\n",
    "        for i, feature in enumerate(features_names):\n",
    "            offset = numpyro.sample(f\"offset_{feature}\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "            priors.append(numpyro.deterministic(f\"beta_{feature}\", mus[i] + offset * sigmas[i]))\n",
    "        shape = numpyro.sample(\"shape\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "\n",
    "    # Expected value\n",
    "    mu = avg_salary[occ]\n",
    "    for i, feature in enumerate(features_names):\n",
    "        mu += priors[i][occ] * X[:,i]\n",
    "\n",
    "    mu = jnp.exp(mu)\n",
    "    rate = shape[occ] / mu\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"data\", X.shape[0]):\n",
    "        numpyro.sample(\"salary_hat\", DISTRIBUTIONS[target_dist](concentration=shape[occ], rate=rate), obs=y)\n",
    "\n",
    "def hierarchical_ind_occ(X, y, ind, occ, features_names, from_posterior=None, **init_params_kwargs):\n",
    "    # Initial parameters\n",
    "    mu_dist = init_params_kwargs.get(\"mu_dist\", \"normal\")\n",
    "    mu_params = init_params_kwargs.get(\"mu_params\", {\"loc\": 0, \"scale\": 3})\n",
    "    sigma_dist = init_params_kwargs.get(\"sigma_dist\", \"half_normal\")\n",
    "    sigma_params = init_params_kwargs.get(\"sigma_params\", {\"scale\": 3})\n",
    "    shape_dist = init_params_kwargs.get(\"shape_dist\", \"uniform\")\n",
    "    shape_params = init_params_kwargs.get(\"shape_params\", {\"low\": 1, \"high\": 100})\n",
    "    target_dist = init_params_kwargs.get(\"target_dist\", \"gamma\")\n",
    "\n",
    "    # Hyperpriors\n",
    "    mus_ind = []\n",
    "    sigmas_ind = []\n",
    "    mus_occ = []\n",
    "    sigmas_occ = []\n",
    "    for dim in [\"ind\", \"occ\"]:\n",
    "        if from_posterior is None:\n",
    "            if dim == \"ind\":\n",
    "                mu_avg_salary_ind = numpyro.sample(f\"mu_avg_salary_ind\", DISTRIBUTIONS[mu_dist](**mu_params))\n",
    "                sigma_avg_salary_ind = numpyro.sample(f\"sigma_avg_salary_ind\", DISTRIBUTIONS[sigma_dist](**sigma_params))\n",
    "                for feature in features_names:\n",
    "                    mus_ind.append(numpyro.sample(f\"mu_{feature}_{dim}\", DISTRIBUTIONS[mu_dist](**mu_params)))\n",
    "                    sigmas_ind.append(numpyro.sample(f\"sigma_{feature}_{dim}\", DISTRIBUTIONS[sigma_dist](**sigma_params)))\n",
    "            else:\n",
    "                mu_avg_salary_occ = numpyro.sample(f\"mu_avg_salary_occ\", DISTRIBUTIONS[mu_dist](**mu_params))\n",
    "                sigma_avg_salary_occ = numpyro.sample(f\"sigma_avg_salary_occ\", DISTRIBUTIONS[sigma_dist](**sigma_params))\n",
    "                for feature in features_names:\n",
    "                    mus_occ.append(numpyro.sample(f\"mu_{feature}_{dim}\", DISTRIBUTIONS[mu_dist](**mu_params)))\n",
    "                    sigmas_occ.append(numpyro.sample(f\"sigma_{feature}_{dim}\", DISTRIBUTIONS[sigma_dist](**sigma_params)))\n",
    "            \n",
    "        else:\n",
    "            if dim == \"ind\":\n",
    "                mu_avg_salary_ind = numpyro.sample(f\"mu_avg_salary_ind\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_avg_salary_ind\"].mean(axis=0), \n",
    "                                                                   from_posterior[f\"mu_avg_salary_ind\"].std(axis=0)))\n",
    "                sigma_avg_salary_ind = numpyro.sample(f\"sigma_avg_salary_ind\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_avg_salary_ind\"].mean(axis=0)))\n",
    "                for feature in features_names:\n",
    "                    mus_ind.append(numpyro.sample(f\"mu_{feature}_{dim}\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_{feature}_{dim}\"].mean(axis=0), \n",
    "                                                                   from_posterior[f\"mu_{feature}_{dim}\"].std(axis=0))))\n",
    "                    sigmas_ind.append(numpyro.sample(f\"sigma_{feature}_{dim}\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_{feature}_{dim}\"].mean(axis=0))))\n",
    "            else:\n",
    "                mu_avg_salary_occ = numpyro.sample(f\"mu_avg_salary_occ\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_avg_salary_occ\"].mean(axis=0), \n",
    "                                                                   from_posterior[f\"mu_avg_salary_occ\"].std(axis=0)))\n",
    "                sigma_avg_salary_occ = numpyro.sample(f\"sigma_avg_salary_occ\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_avg_salary_occ\"].mean(axis=0)))\n",
    "                for feature in features_names:\n",
    "                    mus_occ.append(numpyro.sample(f\"mu_{feature}_{dim}\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_{feature}_{dim}\"].mean(axis=0), \n",
    "                                                                   from_posterior[f\"mu_{feature}_{dim}\"].std(axis=0))))\n",
    "                    sigmas_occ.append(numpyro.sample(f\"sigma_{feature}_{dim}\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_{feature}_{dim}\"].mean(axis=0))))\n",
    "            \n",
    "    priors_ind = []\n",
    "    priors_occ = []\n",
    "    with numpyro.plate(f\"industry\", 16):\n",
    "        offset_avg_salary_ind = numpyro.sample(f\"offset_avg_salary_ind\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "        avg_salary_ind = numpyro.deterministic(f\"avg_salary_ind\", mu_avg_salary_ind + offset_avg_salary_ind * sigma_avg_salary_ind)\n",
    "        for i, feature in enumerate(features_names):\n",
    "            offset = numpyro.sample(f\"offset_{feature}_ind\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "            priors_ind.append(numpyro.deterministic(f\"beta_{feature}_ind\", mus_ind[i] + offset * sigmas_ind[i]))\n",
    "        shape_ind = numpyro.sample(\"shape_ind\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "    \n",
    "    with numpyro.plate(f\"occupation\", 24):\n",
    "        offset_avg_salary_occ = numpyro.sample(f\"offset_avg_salary_occ\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "        avg_salary_occ = numpyro.deterministic(f\"avg_salary_occ\", mu_avg_salary_occ + offset_avg_salary_occ * sigma_avg_salary_occ)\n",
    "        for i, feature in enumerate(features_names):\n",
    "            offset = numpyro.sample(f\"offset_{feature}_occ\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "            priors_occ.append(numpyro.deterministic(f\"beta_{feature}_occ\", mus_occ[i] + offset * sigmas_occ[i]))\n",
    "        shape_occ = numpyro.sample(\"shape_occ\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "\n",
    "\n",
    "    # Expected value\n",
    "    mu = avg_salary_ind[ind] + avg_salary_occ[occ]\n",
    "    for i, feature in enumerate(features_names):\n",
    "        mu += priors_ind[i][ind] * X[:,i] + priors_occ[i][occ] * X[:,i]\n",
    "\n",
    "    shape = shape_ind[ind] + shape_occ[occ]\n",
    "\n",
    "    mu = jnp.exp(mu)\n",
    "    rate = shape / mu\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"data\", X.shape[0]):\n",
    "        numpyro.sample(\"salary_hat\", DISTRIBUTIONS[target_dist](concentration=shape, rate=rate), obs=y)\n",
    "\n",
    "def hierarchical_lognormal(X, y, ind, occ, features_names, from_posterior=None, **init_params_kwargs):\n",
    "    # Initial parameters\n",
    "    mu_dist = init_params_kwargs.get(\"mu_dist\", \"normal\")\n",
    "    mu_params = init_params_kwargs.get(\"mu_params\", {\"loc\": 0, \"scale\": 3})\n",
    "    sigma_dist = init_params_kwargs.get(\"sigma_dist\", \"half_normal\")\n",
    "    sigma_params = init_params_kwargs.get(\"sigma_params\", {\"scale\": 3})\n",
    "    shape_dist = init_params_kwargs.get(\"shape_dist\", \"exponential\")\n",
    "    shape_params = init_params_kwargs.get(\"shape_params\", {\"rate\": 1})\n",
    "    target_dist = init_params_kwargs.get(\"target_dist\", \"log-normal\")\n",
    "\n",
    "    # Hyperpriors\n",
    "    mus_ind = []\n",
    "    sigmas_ind = []\n",
    "    mus_occ = []\n",
    "    sigmas_occ = []\n",
    "    for dim in [\"ind\", \"occ\"]:\n",
    "        if from_posterior is None:\n",
    "            if dim == \"ind\":\n",
    "                mu_avg_salary_ind = numpyro.sample(f\"mu_avg_salary_ind\", DISTRIBUTIONS[mu_dist](**mu_params))\n",
    "                sigma_avg_salary_ind = numpyro.sample(f\"sigma_avg_salary_ind\", DISTRIBUTIONS[sigma_dist](**sigma_params))\n",
    "                for feature in features_names:\n",
    "                    mus_ind.append(numpyro.sample(f\"mu_{feature}_{dim}\", DISTRIBUTIONS[mu_dist](**mu_params)))\n",
    "                    sigmas_ind.append(numpyro.sample(f\"sigma_{feature}_{dim}\", DISTRIBUTIONS[sigma_dist](**sigma_params)))\n",
    "            else:\n",
    "                mu_avg_salary_occ = numpyro.sample(f\"mu_avg_salary_occ\", DISTRIBUTIONS[mu_dist](**mu_params))\n",
    "                sigma_avg_salary_occ = numpyro.sample(f\"sigma_avg_salary_occ\", DISTRIBUTIONS[sigma_dist](**sigma_params))\n",
    "                for feature in features_names:\n",
    "                    mus_occ.append(numpyro.sample(f\"mu_{feature}_{dim}\", DISTRIBUTIONS[mu_dist](**mu_params)))\n",
    "                    sigmas_occ.append(numpyro.sample(f\"sigma_{feature}_{dim}\", DISTRIBUTIONS[sigma_dist](**sigma_params)))\n",
    "            \n",
    "        else:\n",
    "            if dim == \"ind\":\n",
    "                mu_avg_salary_ind = numpyro.sample(f\"mu_avg_salary_ind\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_avg_salary_ind\"].mean(axis=0), from_posterior[f\"mu_avg_salary_ind\"].std(axis=0)))\n",
    "                sigma_avg_salary_ind = numpyro.sample(f\"sigma_avg_salary_ind\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_avg_salary_ind\"].mean(axis=0)))\n",
    "                for feature in features_names:\n",
    "                    mus_ind.append(numpyro.sample(f\"mu_{feature}_{dim}\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_{feature}_{dim}\"].mean(axis=0), from_posterior[f\"mu_{feature}_{dim}\"].std(axis=0))))\n",
    "                    sigmas_ind.append(numpyro.sample(f\"sigma_{feature}_{dim}\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_{feature}_{dim}\"].mean(axis=0))))\n",
    "            else:\n",
    "                mu_avg_salary_occ = numpyro.sample(f\"mu_avg_salary_occ\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_avg_salary_occ\"].mean(axis=0), from_posterior[f\"mu_avg_salary_occ\"].std(axis=0)))\n",
    "                sigma_avg_salary_occ = numpyro.sample(f\"sigma_avg_salary_occ\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_avg_salary_occ\"].mean(axis=0)))\n",
    "                for feature in features_names:\n",
    "                    mus_occ.append(numpyro.sample(f\"mu_{feature}_{dim}\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_{feature}_{dim}\"].mean(axis=0), from_posterior[f\"mu_{feature}_{dim}\"].std(axis=0))))\n",
    "                    sigmas_occ.append(numpyro.sample(f\"sigma_{feature}_{dim}\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_{feature}_{dim}\"].mean(axis=0))))\n",
    "            \n",
    "    priors_ind = []\n",
    "    priors_occ = []\n",
    "    with numpyro.plate(f\"industry\", 16):\n",
    "        offset_avg_salary_ind = numpyro.sample(f\"offset_avg_salary_ind\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "        avg_salary_ind = numpyro.deterministic(f\"avg_salary_ind\", mu_avg_salary_ind + offset_avg_salary_ind * sigma_avg_salary_ind)\n",
    "        for i, feature in enumerate(features_names):\n",
    "                offset = numpyro.sample(f\"offset_{feature}_ind\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "                priors_ind.append(numpyro.deterministic(f\"beta_{feature}_ind\", mus_ind[i] + offset * sigmas_ind[i]))\n",
    "    \n",
    "    with numpyro.plate(f\"occupation\", 24):\n",
    "        offset_avg_salary_occ = numpyro.sample(f\"offset_avg_salary_occ\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "        avg_salary_occ = numpyro.deterministic(f\"avg_salary_occ\", mu_avg_salary_occ + offset_avg_salary_occ * sigma_avg_salary_occ)\n",
    "        for i, feature in enumerate(features_names):\n",
    "                offset = numpyro.sample(f\"offset_{feature}_occ\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "                priors_occ.append(numpyro.deterministic(f\"beta_{feature}_occ\", mus_ind[i] + offset * sigmas_ind[i]))\n",
    "\n",
    "    sigma = numpyro.sample(\"shape\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "\n",
    "    # Expected value\n",
    "    mu = avg_salary_ind[ind] + avg_salary_occ[occ]\n",
    "    for i, feature in enumerate(features_names):\n",
    "        mu += priors_ind[i][ind] * X[:,i] + priors_occ[i][occ] * X[:,i]\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"data\", X.shape[0]):\n",
    "        numpyro.sample(\"salary_hat\", DISTRIBUTIONS[target_dist](loc=mu, scale=sigma), obs=y)\n",
    "\n",
    "def hierarchical_normal(X, y, ind, occ, features_names, from_posterior=None, **init_params_kwargs):\n",
    "    # Initial parameters\n",
    "    mu_dist = init_params_kwargs.get(\"mu_dist\", \"normal\")\n",
    "    mu_params = init_params_kwargs.get(\"mu_params\", {\"loc\": 0, \"scale\": 3})\n",
    "    sigma_dist = init_params_kwargs.get(\"sigma_dist\", \"half_normal\")\n",
    "    sigma_params = init_params_kwargs.get(\"sigma_params\", {\"scale\": 3})\n",
    "    shape_dist = init_params_kwargs.get(\"shape_dist\", \"half_normal\")\n",
    "    shape_params = init_params_kwargs.get(\"shape_params\", {\"rate\": 10})\n",
    "    target_dist = init_params_kwargs.get(\"target_dist\", \"normal\")\n",
    "\n",
    "    # Hyperpriors\n",
    "    mus_ind = []\n",
    "    sigmas_ind = []\n",
    "    mus_occ = []\n",
    "    sigmas_occ = []\n",
    "    for dim in [\"ind\", \"occ\"]:\n",
    "        if from_posterior is None:\n",
    "            if dim == \"ind\":\n",
    "                mu_avg_salary_ind = numpyro.sample(f\"mu_avg_salary_ind\", DISTRIBUTIONS[mu_dist](**mu_params))\n",
    "                sigma_avg_salary_ind = numpyro.sample(f\"sigma_avg_salary_ind\", DISTRIBUTIONS[sigma_dist](**sigma_params))\n",
    "                for feature in features_names:\n",
    "                    mus_ind.append(numpyro.sample(f\"mu_{feature}_{dim}\", DISTRIBUTIONS[mu_dist](**mu_params)))\n",
    "                    sigmas_ind.append(numpyro.sample(f\"sigma_{feature}_{dim}\", DISTRIBUTIONS[sigma_dist](**sigma_params)))\n",
    "            else:\n",
    "                mu_avg_salary_occ = numpyro.sample(f\"mu_avg_salary_occ\", DISTRIBUTIONS[mu_dist](**mu_params))\n",
    "                sigma_avg_salary_occ = numpyro.sample(f\"sigma_avg_salary_occ\", DISTRIBUTIONS[sigma_dist](**sigma_params))\n",
    "                for feature in features_names:\n",
    "                    mus_occ.append(numpyro.sample(f\"mu_{feature}_{dim}\", DISTRIBUTIONS[mu_dist](**mu_params)))\n",
    "                    sigmas_occ.append(numpyro.sample(f\"sigma_{feature}_{dim}\", DISTRIBUTIONS[sigma_dist](**sigma_params)))\n",
    "            \n",
    "        else:\n",
    "            if dim == \"ind\":\n",
    "                mu_avg_salary_ind = numpyro.sample(f\"mu_avg_salary_ind\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_avg_salary_ind\"].mean(axis=0), from_posterior[f\"mu_avg_salary_ind\"].std(axis=0)))\n",
    "                sigma_avg_salary_ind = numpyro.sample(f\"sigma_avg_salary_ind\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_avg_salary_ind\"].mean(axis=0)))\n",
    "                for feature in features_names:\n",
    "                    mus_ind.append(numpyro.sample(f\"mu_{feature}_{dim}\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_{feature}_{dim}\"].mean(axis=0), from_posterior[f\"mu_{feature}_{dim}\"].std(axis=0))))\n",
    "                    sigmas_ind.append(numpyro.sample(f\"sigma_{feature}_{dim}\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_{feature}_{dim}\"].mean(axis=0))))\n",
    "            else:\n",
    "                mu_avg_salary_occ = numpyro.sample(f\"mu_avg_salary_occ\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_avg_salary_occ\"].mean(axis=0), from_posterior[f\"mu_avg_salary_occ\"].std(axis=0)))\n",
    "                sigma_avg_salary_occ = numpyro.sample(f\"sigma_avg_salary_occ\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_avg_salary_occ\"].mean(axis=0)))\n",
    "                for feature in features_names:\n",
    "                    mus_occ.append(numpyro.sample(f\"mu_{feature}_{dim}\", \n",
    "                                            DISTRIBUTIONS[mu_dist](from_posterior[f\"mu_{feature}_{dim}\"].mean(axis=0), from_posterior[f\"mu_{feature}_{dim}\"].std(axis=0))))\n",
    "                    sigmas_occ.append(numpyro.sample(f\"sigma_{feature}_{dim}\", \n",
    "                                                DISTRIBUTIONS[sigma_dist](from_posterior[f\"sigma_{feature}_{dim}\"].mean(axis=0))))\n",
    "            \n",
    "    priors_ind = []\n",
    "    priors_occ = []\n",
    "    with numpyro.plate(f\"industry\", 16):\n",
    "        offset_avg_salary_ind = numpyro.sample(f\"offset_avg_salary_ind\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "        avg_salary_ind = numpyro.deterministic(f\"avg_salary_ind\", mu_avg_salary_ind + offset_avg_salary_ind * sigma_avg_salary_ind)\n",
    "        for i, feature in enumerate(features_names):\n",
    "                offset = numpyro.sample(f\"offset_{feature}_ind\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "                priors_ind.append(numpyro.deterministic(f\"beta_{feature}_ind\", mus_ind[i] + offset * sigmas_ind[i]))\n",
    "    \n",
    "    with numpyro.plate(f\"occupation\", 24):\n",
    "        offset_avg_salary_occ = numpyro.sample(f\"offset_avg_salary_occ\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "        avg_salary_occ = numpyro.deterministic(f\"avg_salary_occ\", mu_avg_salary_occ + offset_avg_salary_occ * sigma_avg_salary_occ)\n",
    "        for i, feature in enumerate(features_names):\n",
    "                offset = numpyro.sample(f\"offset_{feature}_occ\", DISTRIBUTIONS[\"normal\"](loc=0, scale=1))\n",
    "                priors_occ.append(numpyro.deterministic(f\"beta_{feature}_occ\", mus_ind[i] + offset * sigmas_ind[i]))\n",
    "\n",
    "    sigma = numpyro.sample(\"shape\", DISTRIBUTIONS[shape_dist](**shape_params))\n",
    "\n",
    "    # Expected value\n",
    "    mu = avg_salary_ind[ind] + avg_salary_occ[occ]\n",
    "    for i, feature in enumerate(features_names):\n",
    "        mu += priors_ind[i][ind] * X[:,i] + priors_occ[i][occ] * X[:,i]\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"data\", X.shape[0]):\n",
    "        numpyro.sample(\"salary_hat\", DISTRIBUTIONS[target_dist](loc=mu, scale=sigma), obs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(year, data, columns=None, occ_dim=False, samples=None):\n",
    "    # Prepare data for running the model\n",
    "    if columns is None:\n",
    "        columns = [\"exp\",\"sex\",\"no_edu\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "                \"undergrad_edu\", \"graduate_edu\", \"age\", \"tenure\", \"union\", \"public_sector\", \"self_emp\"]\n",
    "        \n",
    "    if samples is None:\n",
    "        dataset = data.query(f'year == {year}').copy()\n",
    "    else:\n",
    "        dataset = data.query(f'year == {year}').sample(samples, random_state=0).copy()\n",
    "\n",
    "    X = dataset[columns].values\n",
    "    y = dataset[\"salary\"].values\n",
    "    ind = dataset[\"ind_codes\"].values\n",
    "    occ = dataset[\"occ_codes\"].values\n",
    "    if occ_dim:\n",
    "        return X, y, ind, occ\n",
    "    else:\n",
    "        return X, y, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_type):\n",
    "    if model_type == \"pooled\":\n",
    "        return pooled\n",
    "    elif model_type == \"no_pooled_ind\":\n",
    "        return no_pooled_ind\n",
    "    elif model_type == \"no_pooled_occ\":\n",
    "        return no_pooled_occ\n",
    "    elif model_type == \"hierarchical_ind\":\n",
    "        return hierarchical_ind\n",
    "    elif model_type == \"hierarchical_occ\":\n",
    "        return hierarchical_occ\n",
    "    elif model_type == \"hierarchical_ind_occ\":\n",
    "        return hierarchical_ind_occ\n",
    "    elif model_type == \"hierarchical_lognormal\":\n",
    "        return hierarchical_lognormal\n",
    "    elif model_type == \"hierarchical_normal\":\n",
    "        return hierarchical_normal\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_coords(mcmc, dimensions, categories, data):\n",
    "    model_coords = {\"coords\": {dim: categories[i] for i, dim in enumerate(dimensions)}}\n",
    "    model_coords[\"coords\"][\"obs\"] = np.arange(0,data.shape[0])\n",
    "    model_coords[\"dims\"] = {}\n",
    "    for latent_var in mcmc._states['z'].keys():\n",
    "        if any(latent_var.startswith(field) for field in [\"avg_\",\"beta_\"]):\n",
    "            model_coords[\"dims\"][latent_var] = [\"industry\"] if latent_var.endswith(\"ind\") else [\"occupation\"]\n",
    "    return model_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model_outputs(mcmc, model, path, *model_params, **model_coords):\n",
    "    # Export mcmc\n",
    "    with open(f\"{path}/model.pickle\", \"wb\") as file:\n",
    "        pickle.dump(mcmc, file)\n",
    "    # Create posterior predictive samples\n",
    "    predictive = Predictive(model, mcmc.get_samples())\n",
    "    posterior_samples = predictive(rng_key, *model_params)\n",
    "    # Add posterior predictive samples to trace\n",
    "    if model_coords=={}:\n",
    "        trace = az.from_numpyro(mcmc, posterior_predictive=posterior_samples)\n",
    "    else:\n",
    "        trace = az.from_numpyro(mcmc, posterior_predictive=posterior_samples, coords=model_coords[\"coords\"], dims=model_coords[\"dims\"])\n",
    "    # Export trace\n",
    "    trace.to_netcdf(f\"{path}/trace.nc\")\n",
    "    # Export summary\n",
    "    summary = az.summary(trace, round_to=5)\n",
    "    summary.to_csv(f\"{path}/summary.csv\")\n",
    "    # Return max Rhat\n",
    "    return summary[\"r_hat\"].max()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and workflow\n",
    "data = pd.read_csv('../datasets/model_dataset_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert industries and occupations to categorical and create codes columns\n",
    "ind_cat = [\n",
    "    'agriculture',\n",
    "    'forestry/oil/mining',\n",
    "    'utilities',\n",
    "    'construction',\n",
    "    'manufacturing',\n",
    "    'trade',\n",
    "    'transportation',\n",
    "    'info/culture',\n",
    "    'finance/real estate',\n",
    "    'scientific/technical',\n",
    "    'business support',\n",
    "    'education',\n",
    "    'health/social',\n",
    "    'accommodation/food',\n",
    "    'other services',\n",
    "    'public admin']\n",
    "data[\"industry\"] = pd.Categorical(data[\"industry\"], categories=ind_cat)\n",
    "data[\"ind_codes\"] = data[\"industry\"].cat.codes\n",
    "\n",
    "occ_cat = ['senior management',\n",
    "    'middle management',\n",
    "    'business/finance professional',\n",
    "    'secretarial/administrative',\n",
    "    'natural/sciences professional',\n",
    "    'technical specialist',\n",
    "    'health professional',\n",
    "    'health assistant',\n",
    "    'teachers/professors',\n",
    "    'government/religion services',\n",
    "    'protective services',\n",
    "    'childcare/home support',\n",
    "    'art/culture occupations',\n",
    "    'clerical/supervisor',\n",
    "    'chefs/food services',\n",
    "    'sales/service',\n",
    "    'clerks/cashiers',\n",
    "    'construction trades',\n",
    "    'transport/equipment operators',\n",
    "    'trade helper/labourer',\n",
    "    'trades contractors/supervisors',\n",
    "    'other trades',\n",
    "    'operators/assemblers',\n",
    "    'manufacturing labourer']\n",
    "data[\"occup\"] = pd.Categorical(data[\"occup\"], categories=occ_cat)\n",
    "data[\"occ_codes\"] = data[\"occup\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique years and sort them\n",
    "years = data[\"year\"].unique()\n",
    "years.sort()\n",
    "\n",
    "# Define features\n",
    "feature_names = [\"exp\",\"sex\",\"no_edu\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "\"undergrad_edu\", \"graduate_edu\", \"age\", \"tenure\", \"union\", \"public_sector\", \"self_emp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split (training and testing)\n",
    "# NOTE: Data before 2008 is used for training and data after 2008 is used for validating the model\n",
    "data = data.query(\"year < 2008\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to store standardization parameters\n",
    "standardization_params = {\n",
    "    \"exp\": {\"mean\": data[\"exp\"].mean(), \"std\": data[\"exp\"].std()},\n",
    "    \"age\": {\"mean\": data[\"age\"].mean(), \"std\": data[\"age\"].std()},\n",
    "    \"tenure\": {\"mean\": data[\"tenure\"].mean(), \"std\": data[\"tenure\"].std()}\n",
    "}\n",
    "\n",
    "# Export standardization parameters (for be used in the validation step)\n",
    "with open(\"src/standardization_params.json\", \"w\") as file:\n",
    "    json.dump(standardization_params, file)\n",
    "\n",
    "# Standardize data\n",
    "data[\"exp\"] = (data[\"exp\"] - data[\"exp\"].mean()) / data[\"exp\"].std()\n",
    "data[\"age\"] = (data[\"age\"] - data[\"age\"].mean()) / data[\"age\"].std()\n",
    "data[\"tenure\"] = (data[\"tenure\"] - data[\"tenure\"].mean()) / data[\"tenure\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"pooled\"\n",
    "model_type = \"pooled\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:10<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00421\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:12<00:00, 15.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00822\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:09<00:00, 28.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00494\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:34<00:00, 57.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0022\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:24<00:00, 81.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0026\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:25<00:00, 78.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0022\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:22<00:00, 88.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00231\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:23<00:00, 83.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00228\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:21<00:00, 91.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00228\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:29<00:00, 66.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00326\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:23<00:00, 83.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00224\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:24<00:00, 82.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00303\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, ind = filter_data(year, data)\n",
    "    # Run model\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, feature_names]\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooled | Regularized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"pooled-reg\"\n",
    "model_type = \"pooled\" # NOTE: pooled, no_pooled, hierarchical\n",
    "init_params_kwargs = {\n",
    "    \"prior_dist\": \"laplace\",\n",
    "    \"prior_params\": {\"loc\": 0, \"scale\": 0.01},\n",
    "    \"shape_dist\": \"uniform\",\n",
    "    \"shape_params\": {\"low\": 1, \"high\": 100},\n",
    "    \"target_dist\": \"gamma\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:20<00:00, 24.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00299\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:55<00:00, 35.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00339\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:59<00:00, 33.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00283\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:01<00:00, 32.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00389\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:08<00:00, 29.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00514\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:49<00:00, 18.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00588\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:05<00:00, 30.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00248\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:03<00:00, 31.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00512\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:09<00:00, 28.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00308\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:03<00:00, 31.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00199\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:05<00:00, 30.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00332\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:00<00:00, 32.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00396\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, ind = filter_data(year, data)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names, **init_params_kwargs)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, feature_names]\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names, samples, **init_params_kwargs)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No-pooled | Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"no-pooled-ind\"\n",
    "model_type = \"no_pooled_ind\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [50:59<00:00,  1.53s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00839\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [16:49<00:00,  1.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00877\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [11:08<00:00,  2.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00583\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [08:50<00:00,  3.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00576\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:57<00:00,  4.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00641\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:12<00:00, 27.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00541\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:26<00:00,  5.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00596\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:31<00:00,  5.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00603\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:24<00:00,  5.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0051\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:27<00:00,  5.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00529\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [07:03<00:00,  4.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00464\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:20<00:00,  5.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00449\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, ind = filter_data(year, data)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, feature_names]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No-pooled | Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"no-pooled-occ\"\n",
    "model_type = \"no_pooled_occ\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:27:50<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00993\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [18:01<00:00,  1.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00603\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [11:49<00:00,  2.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00564\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [09:52<00:00,  3.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0052\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [08:03<00:00,  4.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0076\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:20<00:00, 24.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00821\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [07:41<00:00,  4.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00706\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [07:27<00:00,  4.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00718\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:50<00:00,  4.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00694\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [07:26<00:00,  4.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00778\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [07:54<00:00,  4.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0081\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [07:06<00:00,  4.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00797\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, _, occ = filter_data(year, data, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, occ, feature_names)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, occ, feature_names]\n",
    "        model_coords = set_coords(mcmc, \"occupation\", occ_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, occ, feature_names, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No-pooled | Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"no-pooled-reg\"\n",
    "model_type = \"no_pooled\" # NOTE: pooled, no_pooled, hierarchical\n",
    "init_params_kwargs = {\n",
    "    \"prior_dist\": \"laplace\",\n",
    "    \"prior_params\": {\"loc\": 0, \"scale\": 0.01},\n",
    "    \"shape_dist\": \"uniform\",\n",
    "    \"shape_params\": {\"low\": 1, \"high\": 100},\n",
    "    \"target_dist\": \"gamma\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [07:50<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00939\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [07:02<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00933\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [07:34<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00907\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:25<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00947\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:44<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0085\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:12<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00769\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [05:15<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00787\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:51<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01007\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [05:54<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00809\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [05:02<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00754\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [05:04<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01012\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [05:16<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0074\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, ind = filter_data(year, data)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names, **init_params_kwargs)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, feature_names]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names, samples, **init_params_kwargs)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical | Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"hierarchical-ind\"\n",
    "model_type = \"hierarchical_ind\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:19:46<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01987\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [44:57<00:00,  1.35s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01035\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [24:56<00:00,  1.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00777\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [12:42<00:00,  2.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00562\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [09:27<00:00,  3.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00967\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:09<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01051\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [09:09<00:00,  3.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00655\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [08:53<00:00,  3.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00637\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [11:27<00:00,  2.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00691\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [12:47<00:00,  2.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0045\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [13:49<00:00,  2.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00572\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [12:25<00:00,  2.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00519\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, ind = filter_data(year, data)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, feature_names]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical | Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"hierarchical-occ\"\n",
    "model_type = \"hierarchical_occ\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:54:48<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.03455\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:42:46<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01478\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [37:26<00:00,  1.12s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00663\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [19:24<00:00,  1.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00628\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [14:51<00:00,  2.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00931\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:10<00:00, 15.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00749\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [13:14<00:00,  2.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00721\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [12:28<00:00,  2.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00769\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [12:11<00:00,  2.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0073\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [12:47<00:00,  2.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00676\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [13:07<00:00,  2.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00779\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [12:17<00:00,  2.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0078\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, _, occ = filter_data(year, data, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, occ, feature_names)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, occ, feature_names]\n",
    "        model_coords = set_coords(mcmc, \"occupation\", occ_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, occ, feature_names, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, occ, feature_names]\n",
    "        model_coords = set_coords(mcmc, \"occupation\", occ_cat, X)\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical | Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"hierarchical-reg\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical\n",
    "init_params_kwargs = {\n",
    "    \"mu_dist\": \"laplace\",\n",
    "    \"mu_params\": {\"loc\": 0, \"scale\": 0.001},\n",
    "    \"sigma_dist\": \"half_normal\",\n",
    "    \"sigma_params\": {\"scale\": 0.001},\n",
    "    \"shape_dist\": \"uniform\",\n",
    "    \"shape_params\": {\"low\": 1, \"high\": 100},\n",
    "    \"target_dist\": \"gamma\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [09:59<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00698\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:43<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01155\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [04:58<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01038\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [04:13<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00669\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [03:42<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00713\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:56<00:00, 11.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00597\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [03:14<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00511\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:48<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00635\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [03:10<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00578\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:44<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00838\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [03:25<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00691\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:58<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00697\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, ind = filter_data(year, data)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names, **init_params_kwargs)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, feature_names]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names, samples, **init_params_kwargs)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical | Industry & Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"hierarchical-ind-occ\"\n",
    "model_type = \"hierarchical_ind_occ\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/hierarchical-ind-occ/1999/model.pickle\", \"rb\") as file:\n",
    "    mcmc = pickle.load(file)\n",
    "samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:48:06<00:00,  5.04s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01917\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [25:43<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00697\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:43:37<00:00,  4.91s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00957\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [2:38:07<00:00,  4.74s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00893\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:32:47<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00796\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:29:29<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00944\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:26:47<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00554\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [49:40<00:00,  1.49s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00878\n"
     ]
    }
   ],
   "source": [
    "years = list(range(2000, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, ind, occ = filter_data(year, data, columns=None, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, feature_names)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, feature_names]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, feature_names, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, feature_names]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical log-normal | Industry & Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"hierarchical-lognormal\"\n",
    "model_type = \"hierarchical_lognormal\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/hierarchical-lognormal/1998/model.pickle\", \"rb\") as file:\n",
    "    mcmc = pickle.load(file)\n",
    "samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [55:20<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00777\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup:  32%|███▏      | 630/2000 [20:54<44:01,  1.93s/it] "
     ]
    }
   ],
   "source": [
    "years = list(range(1999, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, ind, occ = filter_data(year, data, columns=None, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, feature_names)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, feature_names]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, feature_names, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, feature_names]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical normal | Industry & Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"hierarchical-normal\"\n",
    "model_type = \"hierarchical_normal\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [1:13:46<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00709\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [33:47<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00937\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [08:01<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00789\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [18:48<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00654\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [22:00<00:00,  1.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00677\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [11:04<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00553\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [12:47<00:00,  2.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0086\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [10:36<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00899\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [09:47<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00602\n",
      ">>>>>>>>>>>>>>>>> year 2008 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [08:43<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00788\n",
      ">>>>>>>>>>>>>>>>> year 2009 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [07:17<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00648\n",
      ">>>>>>>>>>>>>>>>> year 2010 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [06:57<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00683\n",
      ">>>>>>>>>>>>>>>>> year 2011 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [07:45<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00777\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, ind, occ = filter_data(year, data, columns=None, occ_dim=True)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, feature_names)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, occ, feature_names]\n",
    "        model_coords = set_coords(mcmc, [\"industry\",\"occupation\"], [ind_cat, occ_cat], X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, occ, feature_names, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models (variable selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS1 - NO self_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS1-no_self_emp\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:59<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00705\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:58<00:00, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00772\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:05<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00586\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:54<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00715\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:08<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00753\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:38<00:00, 20.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00779\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:55<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00815\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:05<00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00559\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:49<00:00, 18.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00548\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:31<00:00, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0081\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\",\"sex\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "                \"undergrad_edu\", \"graduate_edu\", \"age\", \"tenure\", \"union\",\n",
    "                \"part_time\", \"public_sector\"]\n",
    "    X, y, ind = filter_data(year, data, columns=columns)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, columns]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS2 - NO public sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS2-no_public_sector\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:49<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00695\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:08<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00663\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:01<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00809\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:00<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00506\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:59<00:00, 16.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00749\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:23<00:00, 24.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00491\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:53<00:00, 17.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00669\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:49<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00918\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:01<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00694\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:51<00:00, 17.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00651\n"
     ]
    }
   ],
   "source": [
    "compilate_samples = []\n",
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\",\"sex\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "                \"undergrad_edu\", \"graduate_edu\", \"age\", \"tenure\", \"union\",\n",
    "                \"part_time\"]\n",
    "    X, y, ind = filter_data(year, data, columns=columns)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, columns]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS3 - NO part_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS3-no_part_time\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:42<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00527\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:49<00:00, 18.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00464\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:51<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00535\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:50<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00575\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:53<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00463\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:33<00:00, 21.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00478\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:51<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00898\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:46<00:00, 18.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00686\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:00<00:00, 16.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00531\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:47<00:00, 18.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00471\n"
     ]
    }
   ],
   "source": [
    "compilate_samples = []\n",
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\",\"sex\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "                \"undergrad_edu\", \"graduate_edu\", \"age\", \"tenure\", \"union\"]\n",
    "    X, y, ind = filter_data(year, data, columns=columns)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, columns]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS4 - NO union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS4-no_union\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [03:03<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00581\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:49<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00636\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:47<00:00, 18.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00629\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:53<00:00, 17.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00515\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:49<00:00, 18.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01087\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:22<00:00, 24.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00679\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:47<00:00, 18.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00836\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:38<00:00, 20.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00758\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:42<00:00, 19.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00774\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:50<00:00, 18.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00427\n"
     ]
    }
   ],
   "source": [
    "compilate_samples = []\n",
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\",\"sex\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "                \"undergrad_edu\", \"graduate_edu\", \"age\", \"tenure\"]\n",
    "    X, y, ind = filter_data(year, data, columns=columns)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, columns]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS5 - NO tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS5-no_tenure\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:18<00:00, 14.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00504\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:42<00:00, 19.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00735\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup:   1%|▏         | 29/2000 [00:33<37:34,  1.14s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/avena/Documents/Thesis/LabourSIM/Models/Wages/notebooks/run_models.ipynb Cell 55\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/avena/Documents/Thesis/LabourSIM/Models/Wages/notebooks/run_models.ipynb#Y110sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/avena/Documents/Thesis/LabourSIM/Models/Wages/notebooks/run_models.ipynb#Y110sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     mcmc \u001b[39m=\u001b[39m MCMC(kernel, num_warmup\u001b[39m=\u001b[39mtune, num_samples\u001b[39m=\u001b[39mdraws, num_chains\u001b[39m=\u001b[39mchains, chain_method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvectorized\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/avena/Documents/Thesis/LabourSIM/Models/Wages/notebooks/run_models.ipynb#Y110sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     mcmc\u001b[39m.\u001b[39;49mrun(rng_key, X, y, ind, columns, samples)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/avena/Documents/Thesis/LabourSIM/Models/Wages/notebooks/run_models.ipynb#Y110sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     samples \u001b[39m=\u001b[39m mcmc\u001b[39m.\u001b[39mget_samples()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/avena/Documents/Thesis/LabourSIM/Models/Wages/notebooks/run_models.ipynb#Y110sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m# Save model outputs and calculate max Rhat\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/numpyro/lib/python3.11/site-packages/numpyro/infer/mcmc.py:643\u001b[0m, in \u001b[0;36mMCMC.run\u001b[0;34m(self, rng_key, extra_fields, init_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    642\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchain_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvectorized\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 643\u001b[0m     states, last_state \u001b[39m=\u001b[39m partial_map_fn(map_args)\n\u001b[1;32m    644\u001b[0m     \u001b[39m# swap num_samples x num_chains to num_chains x num_samples\u001b[39;00m\n\u001b[1;32m    645\u001b[0m     states \u001b[39m=\u001b[39m tree_map(\u001b[39mlambda\u001b[39;00m x: jnp\u001b[39m.\u001b[39mswapaxes(x, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m), states)\n",
      "File \u001b[0;32m~/miniconda3/envs/numpyro/lib/python3.11/site-packages/numpyro/infer/mcmc.py:440\u001b[0m, in \u001b[0;36mMCMC._single_chain_mcmc\u001b[0;34m(self, init, args, kwargs, collect_fields)\u001b[0m\n\u001b[1;32m    434\u001b[0m collection_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collection_params[\u001b[39m\"\u001b[39m\u001b[39mcollection_size\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    435\u001b[0m collection_size \u001b[39m=\u001b[39m (\n\u001b[1;32m    436\u001b[0m     collection_size\n\u001b[1;32m    437\u001b[0m     \u001b[39mif\u001b[39;00m collection_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[39melse\u001b[39;00m collection_size \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthinning\n\u001b[1;32m    439\u001b[0m )\n\u001b[0;32m--> 440\u001b[0m collect_vals \u001b[39m=\u001b[39m fori_collect(\n\u001b[1;32m    441\u001b[0m     lower_idx,\n\u001b[1;32m    442\u001b[0m     upper_idx,\n\u001b[1;32m    443\u001b[0m     sample_fn,\n\u001b[1;32m    444\u001b[0m     init_val,\n\u001b[1;32m    445\u001b[0m     transform\u001b[39m=\u001b[39;49m_collect_fn(collect_fields),\n\u001b[1;32m    446\u001b[0m     progbar\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprogress_bar,\n\u001b[1;32m    447\u001b[0m     return_last_val\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    448\u001b[0m     thinning\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthinning,\n\u001b[1;32m    449\u001b[0m     collection_size\u001b[39m=\u001b[39;49mcollection_size,\n\u001b[1;32m    450\u001b[0m     progbar_desc\u001b[39m=\u001b[39;49mpartial(_get_progbar_desc_str, lower_idx, phase),\n\u001b[1;32m    451\u001b[0m     diagnostics_fn\u001b[39m=\u001b[39;49mdiagnostics,\n\u001b[1;32m    452\u001b[0m     num_chains\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_chains \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchain_method \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mparallel\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m )\n\u001b[1;32m    454\u001b[0m states, last_val \u001b[39m=\u001b[39m collect_vals\n\u001b[1;32m    455\u001b[0m \u001b[39m# Get first argument of type `HMCState`\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/numpyro/lib/python3.11/site-packages/numpyro/util.py:367\u001b[0m, in \u001b[0;36mfori_collect\u001b[0;34m(lower, upper, body_fun, init_val, transform, progbar, return_last_val, collection_size, thinning, **progbar_opts)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39mwith\u001b[39;00m tqdm\u001b[39m.\u001b[39mtrange(upper) \u001b[39mas\u001b[39;00m t:\n\u001b[1;32m    366\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m t:\n\u001b[0;32m--> 367\u001b[0m         vals \u001b[39m=\u001b[39m jit(_body_fn)(i, vals)\n\u001b[1;32m    368\u001b[0m         t\u001b[39m.\u001b[39mset_description(progbar_desc(i), refresh\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    369\u001b[0m         \u001b[39mif\u001b[39;00m diagnostics_fn:\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(_cls, step_size, inverse_mass_matrix, mass_matrix_sqrt, mass_matrix_sqrt_inv, ss_state, mm_state, window_idx, rng_key)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compilate_samples = []\n",
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\",\"sex\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "                \"undergrad_edu\", \"graduate_edu\", \"age\"]\n",
    "    X, y, ind = filter_data(year, data, columns=columns)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, columns]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS6 - NO Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS6-no_age\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:39<00:00, 12.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00474\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:47<00:00, 18.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00614\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:42<00:00, 19.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0071\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:47<00:00, 18.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00598\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:32<00:00, 21.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00384\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:32<00:00, 21.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00587\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:20<00:00, 24.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00592\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:30<00:00, 22.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01022\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:27<00:00, 22.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01124\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:37<00:00, 20.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00832\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:33<00:00, 21.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00511\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:27<00:00, 22.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00441\n",
      ">>>>>>>>>>>>>>>>> year 2008 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:31<00:00, 21.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00504\n",
      ">>>>>>>>>>>>>>>>> year 2009 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:39<00:00, 20.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00602\n",
      ">>>>>>>>>>>>>>>>> year 2010 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:35<00:00, 20.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00594\n",
      ">>>>>>>>>>>>>>>>> year 2011 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:28<00:00, 22.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00426\n"
     ]
    }
   ],
   "source": [
    "compilate_samples = []\n",
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\",\"sex\",\"elementary_edu\", \"highschool_edu\", \"postsec_edu\",\n",
    "                \"undergrad_edu\", \"graduate_edu\"]\n",
    "    X, y, ind = filter_data(year, data, columns=columns)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, columns]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS7 - No Education Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS7-no_edu\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:10<00:00, 28.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0062\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:54<00:00, 36.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00489\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:52<00:00, 38.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00545\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:54<00:00, 36.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00486\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:53<00:00, 37.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00254\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:44<00:00, 45.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0043\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:53<00:00, 37.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00351\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:55<00:00, 35.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00543\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:58<00:00, 34.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00615\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:50<00:00, 39.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00625\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:00<00:00, 32.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00451\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:57<00:00, 34.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00773\n",
      ">>>>>>>>>>>>>>>>> year 2008 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:51<00:00, 38.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01413\n",
      ">>>>>>>>>>>>>>>>> year 2009 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:56<00:00, 35.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00697\n",
      ">>>>>>>>>>>>>>>>> year 2010 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:50<00:00, 39.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00591\n",
      ">>>>>>>>>>>>>>>>> year 2011 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:48<00:00, 41.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00369\n"
     ]
    }
   ],
   "source": [
    "compilate_samples = []\n",
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\",\"sex\"]\n",
    "    X, y, ind = filter_data(year, data, columns=columns)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, columns]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS8 - No Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS8-no_sex\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:29<00:00, 22.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00783\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:49<00:00, 40.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01649\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:45<00:00, 43.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.007\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:42<00:00, 46.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01442\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:37<00:00, 52.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01009\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:31<00:00, 63.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00558\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:37<00:00, 53.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0086\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:35<00:00, 56.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00466\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:43<00:00, 45.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00529\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:39<00:00, 51.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01144\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:41<00:00, 48.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00547\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:39<00:00, 50.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00666\n",
      ">>>>>>>>>>>>>>>>> year 2008 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:40<00:00, 49.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00589\n",
      ">>>>>>>>>>>>>>>>> year 2009 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:37<00:00, 53.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00705\n",
      ">>>>>>>>>>>>>>>>> year 2010 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:36<00:00, 54.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00812\n",
      ">>>>>>>>>>>>>>>>> year 2011 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:34<00:00, 57.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00543\n"
     ]
    }
   ],
   "source": [
    "compilate_samples = []\n",
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = [\"exp\"]\n",
    "    X, y, ind = filter_data(year, data, columns=columns)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, columns]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection | VS9 - No exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"VS9-no_exp\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:22<00:00, 24.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.02031\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:35<00:00, 55.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.02626\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:31<00:00, 63.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00541\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:29<00:00, 68.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01406\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:33<00:00, 59.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01917\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:17<00:00, 111.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00862\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:27<00:00, 72.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01585\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:28<00:00, 70.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01622\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:27<00:00, 72.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01406\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:29<00:00, 66.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.02289\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:28<00:00, 69.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0064\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:34<00:00, 58.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0053\n",
      ">>>>>>>>>>>>>>>>> year 2008 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:28<00:00, 70.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00668\n",
      ">>>>>>>>>>>>>>>>> year 2009 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:27<00:00, 72.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00503\n",
      ">>>>>>>>>>>>>>>>> year 2010 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:25<00:00, 78.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.01216\n",
      ">>>>>>>>>>>>>>>>> year 2011 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:25<00:00, 79.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00631\n"
     ]
    }
   ],
   "source": [
    "compilate_samples = []\n",
    "years = list(range(1996, 2008))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = []\n",
    "    X, y, ind = filter_data(year, data, columns=columns)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, columns]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical | All vars - No: age & self_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"ALT-no_age_self_emp\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:41<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00646\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:08<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00656\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:00<00:00, 16.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0072\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:51<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00554\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:02<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0055\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:26<00:00, 22.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00904\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:57<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00594\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:50<00:00, 18.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00658\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:55<00:00, 17.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00635\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:03<00:00, 16.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00411\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:14<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00569\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:32<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00499\n",
      ">>>>>>>>>>>>>>>>> year 2008 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:18<00:00, 14.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00594\n",
      ">>>>>>>>>>>>>>>>> year 2009 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:57<00:00, 16.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00647\n",
      ">>>>>>>>>>>>>>>>> year 2010 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:48<00:00, 18.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0074\n",
      ">>>>>>>>>>>>>>>>> year 2011 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:50<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00647\n"
     ]
    }
   ],
   "source": [
    "compilate_samples = []\n",
    "years = list(range(1996, 2012))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = ['exp','sex','elementary_edu','highschool_edu','postsec_edu','undergrad_edu','graduate_edu',\n",
    "               'tenure','union','part_time','public_sector']\n",
    "    X, y, ind = filter_data(year, data, columns=columns)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, columns]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical | All vars - No: age & self_emp & union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"ALT-no_age_self_emp_union\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:46<00:00, 12.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00847\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:55<00:00, 17.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00566\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:53<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0085\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:47<00:00, 18.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00565\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:51<00:00, 17.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0063\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:35<00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00553\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:01<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00585\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:59<00:00, 16.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00488\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:02<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00668\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:02<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00649\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:02<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00509\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:04<00:00, 16.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00598\n",
      ">>>>>>>>>>>>>>>>> year 2008 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:01<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00584\n",
      ">>>>>>>>>>>>>>>>> year 2009 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:03<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00605\n",
      ">>>>>>>>>>>>>>>>> year 2010 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:58<00:00, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00668\n",
      ">>>>>>>>>>>>>>>>> year 2011 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:22<00:00, 14.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00609\n"
     ]
    }
   ],
   "source": [
    "compilate_samples = []\n",
    "years = list(range(1996, 2012))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = ['exp','sex','elementary_edu','highschool_edu','postsec_edu','undergrad_edu','graduate_edu',\n",
    "               'tenure','part_time','public_sector']\n",
    "    X, y, ind = filter_data(year, data, columns=columns)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, columns]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical | All vars - No: age & self_emp & part_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"ALT-no_age_self_emp_part_time\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:45<00:00, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00634\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:01<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00554\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [04:32<00:00,  7.35it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00525\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:57<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0056\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:58<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00695\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:28<00:00, 22.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00629\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:49<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00931\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:51<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.008\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:50<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00544\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:49<00:00, 18.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00592\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:55<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0067\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:58<00:00, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00542\n",
      ">>>>>>>>>>>>>>>>> year 2008 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:59<00:00, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00524\n",
      ">>>>>>>>>>>>>>>>> year 2009 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:59<00:00, 16.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0076\n",
      ">>>>>>>>>>>>>>>>> year 2010 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:57<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00587\n",
      ">>>>>>>>>>>>>>>>> year 2011 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:54<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00592\n"
     ]
    }
   ],
   "source": [
    "compilate_samples = []\n",
    "years = list(range(1996, 2012))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    columns = ['exp','sex','elementary_edu','highschool_edu','postsec_edu','undergrad_edu','graduate_edu',\n",
    "               'tenure','union','public_sector']\n",
    "    X, y, ind = filter_data(year, data, columns=columns)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, columns]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, columns, samples)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical | Weakly informative priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run settings\n",
    "tune = 1000\n",
    "draws = 1000\n",
    "accept_prob = 0.95\n",
    "chains = 4\n",
    "model_name = \"hierarchical-weak-priors\"\n",
    "model_type = \"hierarchical\" # NOTE: pooled, no_pooled, hierarchical\n",
    "init_params_kwargs = {\n",
    "    \"mu_dist\": \"normal\",\n",
    "    \"mu_params\": {\"loc\": 0, \"scale\": 10},\n",
    "    \"sigma_dist\": \"half_normal\",\n",
    "    \"sigma_params\": {\"scale\": 10},\n",
    "    \"shape_dist\": \"uniform\",\n",
    "    \"shape_params\": {\"low\": 1, \"high\": 100},\n",
    "    \"target_dist\": \"gamma\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> year 1996 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [03:43<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00547\n",
      ">>>>>>>>>>>>>>>>> year 1997 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:13<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00729\n",
      ">>>>>>>>>>>>>>>>> year 1998 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:11<00:00, 15.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0078\n",
      ">>>>>>>>>>>>>>>>> year 1999 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:02<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00644\n",
      ">>>>>>>>>>>>>>>>> year 2000 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:09<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00673\n",
      ">>>>>>>>>>>>>>>>> year 2001 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:48<00:00, 18.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00455\n",
      ">>>>>>>>>>>>>>>>> year 2002 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:02<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00556\n",
      ">>>>>>>>>>>>>>>>> year 2003 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:09<00:00, 15.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00723\n",
      ">>>>>>>>>>>>>>>>> year 2004 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:11<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00485\n",
      ">>>>>>>>>>>>>>>>> year 2005 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:05<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0064\n",
      ">>>>>>>>>>>>>>>>> year 2006 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:15<00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00727\n",
      ">>>>>>>>>>>>>>>>> year 2007 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:03<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.0056\n",
      ">>>>>>>>>>>>>>>>> year 2008 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:05<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00488\n",
      ">>>>>>>>>>>>>>>>> year 2009 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:04<00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00766\n",
      ">>>>>>>>>>>>>>>>> year 2010 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [01:56<00:00, 17.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00809\n",
      ">>>>>>>>>>>>>>>>> year 2011 <<<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [02:02<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Rhat: 1.00683\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1996, 2012))\n",
    "model = create_model(model_type)\n",
    "for year in years:\n",
    "    print(f\">>>>>>>>>>>>>>>>> year {year} <<<<<<<<<<<<<<<<<<<\")\n",
    "    # Create output folder\n",
    "    OUTPUT_PATH = f\"../outputs/{model_name}/{year}\"\n",
    "    if not os.path.exists(f\"{OUTPUT_PATH}\"):\n",
    "                os.makedirs(f\"{OUTPUT_PATH}\")\n",
    "    # Filter data\n",
    "    X, y, ind = filter_data(year, data)\n",
    "    # Run model\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "    kernel = NUTS(model, target_accept_prob=accept_prob, init_strategy=init_to_median(num_samples=200))\n",
    "    if year == 1996:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names, **init_params_kwargs)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        model_params = [X, None, ind, feature_names]\n",
    "        model_coords = set_coords(mcmc, \"industry\", ind_cat, X)\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    else:\n",
    "        mcmc = MCMC(kernel, num_warmup=tune, num_samples=draws, num_chains=chains, chain_method=\"vectorized\")\n",
    "        mcmc.run(rng_key, X, y, ind, feature_names, samples, **init_params_kwargs)\n",
    "        samples = mcmc.get_samples()\n",
    "        # Save model outputs and calculate max Rhat\n",
    "        max_rhat = export_model_outputs(mcmc, model, OUTPUT_PATH, *model_params, **model_coords)\n",
    "    print(f\"Max Rhat: {max_rhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
